---
title: "Weekly update 04/12/2019-11/12/2019"
author: "Stephen Coleman"
date: "10/12/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Consensus clustering

I have discovered that the command line version of MDI does not handle sparse categorical data well. I am trying to understand the priors he uses (the most likely source of the problem according to Paul), but a lack of comments apart from such cases as "TODO: add an explicit ``sample from prior" call in here" are making it an uphill battle.

### Comparison command line to MATLAB

```{r load_data, echo = FALSE, results='hide'}
library(tibble)
library(mdiHelpR)

mdi_mason <- readRDS("./Data/cmd_line_358500.rds")
mdi_matlab <- readRDS("./Data/matlab_8080.rds")
consensus_mason <- readRDS("./Data/cmd_line_consensus_clustering.rds")
consensus_matlab_100 <- readRDS("./Data/matlab_consensus_clustering_100.rds")
consensus_matlab_500 <- readRDS("./Data/matlab_consensus_clustering_500.rds")
mdi_matlab_bad_priors <- readRDS("./Data/matlab_bad_priors_1550.rds")

col_pal <- c("#FFFFFF", grDevices::colorRampPalette(RColorBrewer::brewer.pal(n = 7, name = "Blues"))(100))
breaks <- defineBreaks(col_pal, lb = 0, ub = 1)
```

```{r combine_pheatmaps, echo = FALSE}

dataset_1 <- mdi_mason$dataset[[1]]
dataset_2 <- mdi_mason$dataset[[2]]
dataset_3 <- mdi_mason$dataset[[3]]

n_datasets <- length(mdi_mason$dataset)
ph_list <- vector("list", 6 * n_datasets)

n_ph <- 10
for (i in 1:n_datasets) {
  dataset <- mdi_mason$dataset[[i]]

  mdi_mason_sim <- mdi_mason$similarity_matrix[mdi_mason$dataset == dataset][[1]]
  mdi_matlab_sim <- mdi_matlab$similarity_matrix[mdi_matlab$dataset == dataset][[1]]
  consensus_mason_sim <- consensus_mason$similarity_matrix[consensus_mason$dataset == dataset][[1]]
  consensus_matlab_100_sim <- consensus_matlab_100$similarity_matrix[consensus_matlab_100$dataset == dataset][[1]]
  consensus_matlab_500_sim <- consensus_matlab_500$similarity_matrix[consensus_matlab_500$dataset == dataset][[1]]
  mdi_matlab_bad_priors_sim <- mdi_matlab_bad_priors$similarity_matrix[mdi_matlab_bad_priors$dataset == dataset][[1]]
  
  mdi_mason_expr <- mdi_mason$expression_data[mdi_mason$dataset == dataset][[1]]
  mdi_matlab_expr <- mdi_matlab$expression_data[mdi_matlab$dataset == dataset][[1]]
  consensus_mason_expr <- consensus_mason$expression_data[consensus_mason$dataset == dataset][[1]]
  consensus_matlab_100_expr <- consensus_matlab_100$expression_data[consensus_matlab_100$dataset == dataset][[1]]
  consensus_matlab_500_expr <- consensus_matlab_500$expression_data[consensus_matlab_500$dataset == dataset][[1]]
  mdi_matlab_bad_priors_expr <- mdi_matlab_bad_priors$expression_data[mdi_matlab_bad_priors$dataset == dataset][[1]]
  
  ph_list[[n_ph * (i - 1) + 1]] <- compareMatrices(mdi_matlab_sim,
    mdi_mason_sim,
    curr_title = paste0(dataset, ": MATLAB vs CMD Line"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 2]] <- compareMatrices(mdi_mason_sim,
    mdi_matlab_sim,
    curr_title = paste0(dataset, ": CMD Line vs MATLAB"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 3]] <- compareMatrices(mdi_matlab_sim,
    consensus_mason_sim,
    curr_title = paste0(dataset, ": MATLAB vs CMD Line consensus"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 4]] <- compareMatrices(mdi_matlab_sim,
    consensus_matlab_100_sim,
    curr_title = paste0(dataset, ": MATLAB vs MATLAB consensus (100)"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 5]] <- compareMatrices(consensus_matlab_100_sim,
    consensus_mason_sim,
    curr_title = paste0(dataset, ": MATLAB consensus (100) vs CMD Line consensus"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 6]] <- compareMatrices(consensus_mason_sim,
    consensus_matlab_100_sim,
    curr_title = paste0(dataset, ": CMD Line consensus vs MATLAB consensus (100)"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 7]] <- compareMatrices(mdi_matlab_sim,
    consensus_matlab_500_sim,
    curr_title = paste0(dataset, ": MATLAB MDI vs MATLAB consensus (500)"),
    col_pal = col_pal,
    col_names = F
  )

  ph_list[[n_ph * (i - 1) + 8]] <- compareMatrices(consensus_matlab_100_sim,
    consensus_matlab_500_sim,
    curr_title = paste0(dataset, ": MATLAB consensus (100) vs MATLAB consensus (500)"),
    col_pal = col_pal,
    col_names = F
  )
  
  ph_list[[n_ph * (i - 1) + 9]] <- compareMatrices(mdi_matlab_sim,
    mdi_matlab_bad_priors_sim,
    curr_title = paste0(dataset, ": MATLAB prior comparison"),
    col_pal = col_pal,
    col_names = F
  )
  
  ph_list[[n_ph * (i - 1) + 10]] <- compareMatrices(mdi_mason_sim,
    mdi_matlab_bad_priors_sim,
    curr_title = paste0(dataset, ": Cmd line vs MATLAB, common priors"),
    col_pal = col_pal,
    col_names = F
  )
}
```

Let's compare the posterior similarity matrices (PSMs) produced by the different methods. Our methods are:

1. Command line MDI (358,500);
2. Command line consensus clustering (1,000 seeds for 500 iterations);
3. MATLAB MDI (8,080 iterations);
4. MATLAB consensus clustering (1,000 seeds for 100 iterations); and
5. MATLAB consensus clustering (1,000 seeds for 500 iterations).

The number of iterations is an odd number for the long chains due to constraints on the HPC.

In each case the MATLAB MDI is being considered our gold standard. This might not be fair as there's no strong reason to think this chain has converged, but it's similar to results to the original MDI paper, so for now it's a good heuristic for checking for sensible results.

We have three datasets, the time course data (which seems most consistent across methods), which is run using the Gaussian Process setting, and then two sparse categorical datasets, the Chip-chip transcription factor data from the Harbison paper and the protein-protein interaction data (Harbison and PPI resepective). Let's look at the comparison of the timecourse data for the MATLAB MDI and Command line MDI: 

```{r mdi_comp_timecourse, echo=FALSE}
ph_list[[1]]
```

Comparing the MATLAB to both forms of consensus clustering:

```{r consensus_comp_timecourse, echo=FALSE}
ph_list[[3]]
ph_list[[4]]
ph_list[[7]]
ph_list[[8]]
```

This is not too bad. There's slightly different stories but quite a lot of agreement too. The real difference is within the categorical datasets:

```{r mdi_comp_categorical, echo = FALSE}
ph_list[[n_ph + 1]]
ph_list[[n_ph + 3]]
ph_list[[n_ph + 4]]
ph_list[[n_ph + 7]]
ph_list[[n_ph + 8]]

ph_list[[2 * n_ph + 1]]
ph_list[[2 * n_ph + 3]]
ph_list[[2 * n_ph + 4]]
ph_list[[2 * n_ph + 7]]
ph_list[[2 * n_ph + 8]]
```

We can see that the consensus clustering works pretty well even with only 100 iterations, but really 500 is a fair bit better.

The priors were finally located in the Command line code. The categorical prior is set to 0.5. In the MATLAB code it's an empiricla prior based upon the proportion of each category across the entire datasets. In our example categorical datasets the priors are then:

\[
\begin{aligned}
\textrm{Command line prior: } &
\begin{pmatrix} 
  0.50 \\ 0.50
\end{pmatrix}, \\ 
\textrm{ MATLAB prior for the Transcription factor data: } &
\begin{pmatrix}
  0.988 \\ 0.012
\end{pmatrix}, \\
\textrm{ MATLAB prior for the PPI data: } & 
\begin{pmatrix}
  0.983 \\
  0.017
\end{pmatrix}
\end{aligned}
\]

A clear difference. To check if this is the source of the issue the MATLAB code was re-run with a prior to match the command line code. The results can be seen below for each dataset:

```{r bad_priors_comp, echo = F}
ph_list[[0 * n_ph + 9]]
ph_list[[0 * n_ph + 10]]

ph_list[[1 * n_ph + 9]]
ph_list[[1 * n_ph + 10]]

ph_list[[2 * n_ph + 9]]
ph_list[[2 * n_ph + 10]]
```

