# Future work {#futureWork}

There are two main aspects to my curently-planned future work; 

1. the immediate next-step, the work to explore consensus clustering more fully; and
2. the long-term plans for the scope of my PhD.

(1) requires investigation of consensus clustering in the multiple dataset case. This involves applying consensus clustering to:
  * multiple-dataset simulations (similar to the single-dataset simulations described in the preceding chapter); and
  * real data.
  
With regards to (2), there are two broad areas that are becoming more interesting to me as possible applications of integrative clustering:
 
* immunology; and
* cancer.

## Consensus clustering

### Current project

Currently I have explored the performance of consensus clustering for Bayesian mixture models. The next step is to extend the simulation study to cover the multiple dataset case. That consensus clustering may be used as an alternative to Bayesian inference in integrative clustering is one of its attractions. Investigating performance in this setting, which is an area where MLE models do not extend to and sampling-based Bayesian models can struggle to scale within, is key to displaying the value of consensus clustering. I have already shown that when many features are present that consensus clustering performs well and quickly in comparison to Bayesian inference. In multi-'omics analyses this problem is present in **each dataset**, exacerbating the problems present in the single dataset case. This can make Bayesian inference unfeasible in this setting. As I have already shown in the single dataset case, a Gibbs sampler can struggle as dimensionality scales, becoming trapped in modes as the likelihood function is a $P$-polynomial. Adding additional parameters for each dataset means that the likelihood surface becomes even more extreme and modes are extremely dense relative to the surrounding space. In this setting I hope that consensus clustering would perform well. A natural comparison for the simulation 
is the ``iCluster`` software [@shen2009integrative; @mo2018fully], a popular 
integrative clustering method.

To finish my current project, I then intend to apply consensus clustering to a real dataset. The Cancer Genome Atlas (**TCGA**) has many datasets that are used in several integrative methods papers. Cancer data is seen as useful for validating a clustering method, as the subtypes (of many cancers) are defined by their 'omics profile. This means that there exists known structure in the data that a method should uncover (at least to some degree). Furthermore, many of the specific datasets have already been studied, so a comparison between methods is enabled. The TCGA Pan-Cancer dataset [@hoadley2014multiplatform] is an ideal example of this; a large enough dimensionality that sampling-based Bayesian inference is not possible and so consensus clustering is a way of applying Bayesian models on this dataset.

To uncover subtypes within cancer data requires that we infer a global clustering. 
I would propose using either Bayesian Consensus Clustering [**BCC**, @lock2013bayesian], Clusternomics [@gabasova2017clusternomics] or else a pipeline applying Kernel Learning Integrative Clustering [**KLIC**, @cabassi2019multiple] to the dataset specific PSMs inferred by Multiple Dataset Integration [**MDI**, @kirk2012bayesian] to generate a global clustering. However, the Clusternomics R package as available on Github does not work in its current state, leaving BCC or else MDI + KLIC.

### Future extensions

Expansions to consensus clustering are possible. Currently consensus clustering
has many of the strengths of Bayesian inference. Extensions to leverage
some of the strengths of _sampling techniques_ could also improve
the ability of consensus clustering to uncover structure. This is not a new idea,
@mclachlan1987bootstrapping proposed bootstrapping as a tool to enable the test
of a single normal density versus a mixture of two normal densities in the 
univariate case and @monti2003consensus proposed used of sampling within their 
implementation of consensus clustering. More recently, Sampling items without 
replacement and feature-selection have been shown to yield control of the sample
familywise error and also improve structure estimation [@meinshausen2010stability].
The idea of sampling features and items is the underlying mechanism of the 
Random Forest algorithm [@breiman2001random]. Inspired by these, I propose
extending consensus clustering and investigating:

1. The effect of sampling items across chains;
2. The effect of sampling features across chains; and
3. Simultaneously sampling both features and items across chains.

Note that I am proposing random sampling of features rather than feature 
selection in contrast to @meinshausen2010stability. This will lose some of the 
guarantees of sample familywise error, but @meinshausen2010stability state that
their results hold for slightly smaller constants if feature selection is no
better than random.

A problem here is identifying which models find no structure without a visual 
inspection. Finding which chains find which partitions seems non-trivial.
One could take an average consensus matrix as with the implementation described
in the previous sections of this report. However, I think that indentifying
different structures present and identifying which features contribute signal 
would be part of the attraction of this approach (also, which features do not 
contribute). Taking only the average consensus matrix removes this.

Ideally sampling the items would reveal the stability of clusters and provide an
argument for how likely the clusters are to be present in the larger population 
as well as providing some insight into which clusters might split / merge if 
more data is provided. 

As dimensionality is the source of so many problems for the inference, sampling 
features would reduce the relative density of modes enabling better mixing. If 
we sample features that contain no signal, we have seen in the no structure case
that a chain will not discover false signal (although if the number of features 
is not small enough it may stay in the initialised clustering rather than reduce
to no structure). Thus sampling features could help make any signal present more
clear without the fear that the cases where there are no structure will hide any
signal when results are compiled. A condition here would be that one samples a 
sufficiently small number of features that modes are less attractive to each 
chain (to avoid the problems seen in the simulation of small N large P small dm.
I suspect that sampling the items and features would require more chains for 
stable results, but I think that several individual chains would be 
significantly improved, improving the inference overall sufficiently to make the
cost worthwhile.

One could also dismiss chains where no structure is found and isolate which 
features are contributing signal to any partitions uncovered. This would also
help if it is the case that two (or more) reasonable partitions are present.

Note: sampling features might also help if there are several clustering 
structures present (although this is a different problem).

I think that the issue of inference in high $P$ space is still difficult enough
that any improvement that sampling offers is attractive. I also think that
the computational cost of additional chains will be partially offset by each
individual chain becoming quicker due to reducing the dimensionality of the 
problem.


## Future applications


### Immunology

I have said previously that immunology is an area where I think clustering, and specifically integrative clustering, can yield large dividends. Immune-mediated diseases are complex pathologies; integrating all data into analysis of such diseases yields improved understanding compared to investigation at the single view level [@hasin2017multi; @integrative2014integrative]. Investigating diseases and settings where complex molecular biology is unfolding strikes me as a natural application of clustering methods, a large attraction of which is improved interpretability. Furthermore, many immune mediated diseases are known to have a genetic [@dubois2010multiple; @okada2014genetics; @hunt2008newly; @bourges2020resolving] and epigenetic [@soskic2019chromatin] component. It has already been seen in cancer that there exists a large range of immune phenotypes within patients [@varn2016integrative; @hendrickx2017identification]. I would think that within immune-mediated diseases the variety of behaviour within the immune system could be on a similar scale of complexity; thus the combination of leveraging multiple 'omics views simultaneously and inferring $K$ thgrough use of a Dirichlet process could offer insights into patient immune profiles that are currently lacking. Alternatively to clustering using multiple 'omics profiles, one could instead use multiple datasets of gene expression across disease types as the drivers of many of these diseases have been shown to correlate, thus suggesting that sharing information across datasets could boost signal [@burren2020characterisation]. 

I see there being three statistical items of interest for clustering within immunology:

1. Cells: we know that our classification of cells into different groups is simplistic. Each cell is unique; many share broad properties and characteristics, but the pretence that all cells of a certain type are exact clones is misleading. Clustering cells by their gene expression might reveal interesting heterogeneity within populations traditionally viewed as homogeneous. Particularly within patients with diseases associated with specific cell or tissue types, it might be interesting to see if subsets of traditional cell groups are behaving significantly differently by assessing all genes present, rather than relying on a small number of key signals. 
2. Genes: understanding how genes are expressed differently within different environments is key to understanding localised pathologies like many immune-mediated diseases (such as inflammatory bowel diseases, **IBD**, and type 1 diabetes, **T1D**). Clustering genes:
  
    * across tissues and cell types would be a natural application of Bayesian integrative clustering as uncertainty is quantified and the similarity between tissues may be inferred from the data. Thus tissue heterogeneity will be shown in the final results and we may learn which tissues may contain useful information regarding other tissues that might be harder / more damaging to access for a patient and can be leveraged to inform decisions that the ideal sample tends to be sparse for. 
    * within affected tissue types from multiple diseases to leverage shared signal (e.g. cluster genes using pancreas samples of T1D patients and colon samples from IBD patients, although as these are more commonly studied diseases, ideally data from a rarer autoimmune disease such as Sarcoidosis would be included).
    * across patients and controls within both disease associated tissues and partolling immune cells. Using MDI [@kirk2012bayesian] and the Human Cell Atlas data repository [@regev2017science] to cluster genes in people with the disease state and controls, treating the different disease states and controls as different datasets. Due to the paired dataset correlation parameter in the model, $\phi_{ij}$, datasets will be encouraged to cluster similarly, particularly as I would expect most datasets to have a large level of correlation between many clusters (e.g. house-keeping genes). Thus, any dataset specific clusters would hopefully contain strong signal and might describe novel biology that helps improve our understanding of the disease aetiology. An example of a dataset that would suit this analysis would consist of 4 datasets of gene expression:

      * An example of patrolling immune cells such as CD14+ monocytes collected from the blood stream for both patients and controls; and 
      * Tissue samples of the diseases location, e.g. the pancreas for T1D or the large intestine for IBD, for both patients and controls.
  
    The tissue sample should contain activated immune cells in those suffering the disease state, whereas the circulating immune cells should be deactivated. Any clusters that emerge in the patient specific datasets but not the control datasets would be of interest. Another view that could be of interest is the different clusters emerging between tissue specific expression and the patrolling cell expression that are in the patients but not in the controls.
  
3. Patients: it is now believed that there is greater heterogeneity within many traditional immune-mediated diseases. Clustering patients across multiple 'omics derived from the tissue associated with the disease and other datasets such as patrolling CD4, CD14 cells (i.e. immune cells that are probably not activated due to being away from the inflamed area but demonstrative of what the patients’ immune cells may have appeared prior to disease onset) could be of interest. This would allow subdivision of patients based upon an omics profile rather than purely upon observed phenotype and disease progression (although a validation of the clustering would include correlation between some of the predicted clusters and clinical subtypes).


<!-- I describe briefly a slightly more detailed example of a study of clustering behaviour of genes across disease states using MDI. Using data such as that available at the Human Cell Atlas it might be interesting to cluster genes in people with the disease state and controls, treating the different disease states and controls as different datasets. Due to the paired dataset correlation parameter in the model, $\phi_{ij}$, datasets will be encouraged to cluster similarly, particularly as I would expect most datasets to have a large level of correlation between many clusters (e.g. house-keeping genes). Thus, any dataset specific clusters would hopefully contain strong signal and might describe novel biology that helps improve our understanding of the disease aetiology. The ideal dataset for this would involve 4 datasets of gene expression: -->

<!-- 1. An example of patrolling immune cells such as CD14+ monocytes collected from the blood stream for both patients and controls; and  -->
<!-- 2. Tissue samples of the diseases location, e.g. the pancreas for T1D or the large intestine for IBD, for both patients and controls. -->

<!-- The tissue sample should contain activated immune cells in those suffering the disease state, whereas the circulating immune cells should be deactivated. Any clusters that emerge in the patient specific datasets but not the control datasets would be of interest. Another view that could be of interest is the different clusters emerging between tissue specific expression and the patrolling cell expression that are in the patients but not in the controls. -->

<!-- Use JIVE/MOFA and inspect individual components? This is not clustering, but we still reveal heterogeneity of interest along the different components – if necessary, can apply clustering to the latent space. -->


### Cancer

This area is the traditional application of integrative methods; there are a range of 'omics views available for many different cancer types. The large amount of data available in this realm (such as the Human Tumour Atlas Network, **HTAN**, and TCGA) means that there exist large datasets that offer an opportunity to showcase consensus clustering; the fact that each individual learner is independent within of consensus clustering means that one may leverage a parallel environment to reduce runtimes, allowing use of more data than most Bayesian methods can use in an analysis (as the serial nature of traditional MCMC analysis means that one must reduce the dataset to something feasible for a chain to converge upon in finite time). Ideally the additional data and better ability to incorporate multiple modes means that consensus clustering might unveil new biology within some of these datasets. Using a clustering method which contains uncertainty (partially representing the diversity within cell types, partially model uncertainty) and can model across multiple datasets simultaneously (and may infer the similarity between datasets) strikes me as greatly interesting as we can see within the PSM/CM how certain different partitions are. 

Some of the data that will be available through HTAN include repeated measurements over time. Clustering this data using a mixture of Gaussian processes could be quite exciting. The computational cost of such an analysis is a natural scenario in which to use consensus clustering. Identifying changes in 'omics levels as time progresses could reveal previosuly neglected heterogeneity within the data and while also offering deeper insight into the pathogenesis of the cancers present.