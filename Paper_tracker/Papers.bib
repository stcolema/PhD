
@article{lock_bayesian_2013,
	title = {Bayesian consensus clustering},
	volume = {29},
	issn = {1460-2059, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btt425},
	doi = {10.1093/bioinformatics/btt425},
	abstract = {Motivation: In biomedical research a growing number of platforms and technologies are used to measure diverse but related information, and the task of clustering a set of objects based on multiple sources of data arises in several applications. Most current approaches to multisource clustering either independently determine a separate clustering for each data source or determine a single ‘joint’ clustering for all data sources. There is a need for more flexible approaches that simultaneously model the dependence and the heterogeneity of the data sources.},
	language = {en},
	number = {20},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Lock, Eric F. and Dunson, David B.},
	month = oct,
	year = {2013},
	pages = {2610--2616},
	file = {Lock and Dunson - 2013 - Bayesian consensus clustering.pdf:/home/stephen/Zotero/storage/JDKACSKT/Lock and Dunson - 2013 - Bayesian consensus clustering.pdf:application/pdf}
}

@article{gabasova_clusternomics:_2017,
	title = {Clusternomics: {Integrative} context-dependent clustering for heterogeneous datasets},
	volume = {13},
	issn = {1553-7358},
	shorttitle = {Clusternomics},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1005781},
	doi = {10.1371/journal.pcbi.1005781},
	abstract = {Integrative clustering is used to identify groups of samples by jointly analysing multiple datasets describing the same set of biological samples, such as gene expression, copy number, methylation etc. Most existing algorithms for integrative clustering assume that there is a shared consistent set of clusters across all datasets, and most of the data samples follow this structure. However in practice, the structure across heterogeneous datasets can be more varied, with clusters being joined in some datasets and separated in others. In this paper, we present a probabilistic clustering method to identify groups across datasets that do not share the same cluster structure. The proposed algorithm, Clusternomics, identifies groups of samples that share their global behaviour across heterogeneous datasets. The algorithm models clusters on the level of individual datasets, while also extracting global structure that arises from the local cluster assignments. Clusters on both the local and the global level are modelled using a hierarchical Dirichlet mixture model to identify structure on both levels. We evaluated the model both on simulated and on real-world datasets. The simulated data exemplifies datasets with varying degrees of common structure. In such a setting Clusternomics outperforms existing algorithms for integrative and consensus clustering. In a real-world application, we used the algorithm for cancer subtyping, identifying subtypes of cancer from heterogeneous datasets. We applied the algorithm to TCGA breast cancer dataset, integrating gene expression, miRNA expression, DNA methylation and proteomics. The algorithm extracted clinically meaningful clusters with significantly different survival probabilities. We also evaluated the algorithm on lung and kidney cancer TCGA datasets with high dimensionality, again showing clinically significant results and scalability of the algorithm.},
	language = {en},
	number = {10},
	urldate = {2019-11-13},
	journal = {PLOS Computational Biology},
	author = {Gabasova, Evelina and Reid, John and Wernisch, Lorenz},
	editor = {Morris, Quaid},
	month = oct,
	year = {2017},
	pages = {e1005781},
	file = {Gabasova et al. - 2017 - Clusternomics Integrative context-dependent clust.pdf:/home/stephen/Zotero/storage/WFLZPB5I/Gabasova et al. - 2017 - Clusternomics Integrative context-dependent clust.pdf:application/pdf}
}

@article{mo_fully_2018,
	title = {A fully {Bayesian} latent variable model for integrative clustering analysis of multi-type omics data},
	volume = {19},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/article/19/1/71/3852318},
	doi = {10.1093/biostatistics/kxx017},
	language = {en},
	number = {1},
	urldate = {2019-11-13},
	journal = {Biostatistics},
	author = {Mo, Qianxing and Shen, Ronglai and Guo, Cui and Vannucci, Marina and Chan, Keith S and Hilsenbeck, Susan G},
	month = jan,
	year = {2018},
	pages = {71--86},
	file = {Mo et al. - 2018 - A fully Bayesian latent variable model for integra.pdf:/home/stephen/Zotero/storage/5WT3ERNA/Mo et al. - 2018 - A fully Bayesian latent variable model for integra.pdf:application/pdf}
}

@article{shen_integrative_2009,
	title = {Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis},
	volume = {25},
	issn = {1460-2059, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btp543},
	doi = {10.1093/bioinformatics/btp543},
	abstract = {Motivation: The molecular complexity of a tumor manifests itself at the genomic, epigenomic, transcriptomic and proteomic levels. Genomic proﬁling at these multiple levels should allow an integrated characterization of tumor etiology. However, there is a shortage of effective statistical and bioinformatic tools for truly integrative data analysis. The standard approach to integrative clustering is separate clustering followed by manual integration. A more statistically powerful approach would incorporate all data types simultaneously and generate a single integrated cluster assignment.},
	language = {en},
	number = {22},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Shen, Ronglai and Olshen, Adam B. and Ladanyi, Marc},
	month = nov,
	year = {2009},
	pages = {2906--2912},
	file = {Shen et al. - 2009 - Integrative clustering of multiple genomic data ty.pdf:/home/stephen/Zotero/storage/XWMSEH55/Shen et al. - 2009 - Integrative clustering of multiple genomic data ty.pdf:application/pdf}
}

@article{kirk_bayesian_2012,
	title = {Bayesian correlated clustering to integrate multiple datasets},
	volume = {28},
	issn = {1460-2059, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bts595},
	doi = {10.1093/bioinformatics/bts595},
	abstract = {Motivation: The integration of multiple datasets remains a key challenge in systems biology and genomic medicine. Modern highthroughput technologies generate a broad array of different data types, providing distinct—but often complementary—information. We present a Bayesian method for the unsupervised integrative modelling of multiple datasets, which we refer to as MDI (Multiple Dataset Integration). MDI can integrate information from a wide range of different datasets and data types simultaneously (including the ability to model time series data explicitly using Gaussian processes). Each dataset is modelled using a Dirichlet-multinomial allocation (DMA) mixture model, with dependencies between these models captured through parameters that describe the agreement among the datasets. Results: Using a set of six artificially constructed time series datasets, we show that MDI is able to integrate a significant number of datasets simultaneously, and that it successfully captures the underlying structural similarity between the datasets. We also analyse a variety of real Saccharomyces cerevisiae datasets. In the two-dataset case, we show that MDI’s performance is comparable with the present state-of-the-art. We then move beyond the capabilities of current approaches and integrate gene expression, chromatin immunoprecipitation–chip and protein–protein interaction data, to identify a set of protein complexes for which genes are co-regulated during the cell cycle. Comparisons to other unsupervised data integration techniques—as well as to non-integrative approaches—demonstrate that MDI is competitive, while also providing information that would be difficult or impossible to extract using other methods.},
	language = {en},
	number = {24},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Kirk, Paul and Griffin, Jim E. and Savage, Richard S. and Ghahramani, Zoubin and Wild, David L.},
	month = dec,
	year = {2012},
	pages = {3290--3297},
	file = {Kirk et al. - 2012 - Bayesian correlated clustering to integrate multip.pdf:/home/stephen/Zotero/storage/R2LYT2D4/Kirk et al. - 2012 - Bayesian correlated clustering to integrate multip.pdf:application/pdf}
}

@article{toh_looking_2019,
	title = {Looking beyond the hype: {Applied} {AI} and machine learning in translational medicine},
	volume = {47},
	issn = {23523964},
	shorttitle = {Looking beyond the hype},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352396419305493},
	doi = {10.1016/j.ebiom.2019.08.027},
	abstract = {Big data problems are becoming more prevalent for laboratory scientists who look to make clinical impact. A large part of this is due to increased computing power, in parallel with new technologies for high quality data generation. Both new and old techniques of artiﬁcial intelligence (AI) and machine learning (ML) can now help increase the success of translational studies in three areas: drug discovery, imaging, and genomic medicine. However, ML technologies do not come without their limitations and shortcomings. Current technical limitations and other limitations including governance, reproducibility, and interpretation will be discussed in this article. Overcoming these limitations will enable ML methods to be more powerful for discovery and reduce ambiguity within translational medicine, allowing data-informed decision-making to deliver the next generation of diagnostics and therapeutics to patients quicker, at lowered costs, and at scale.},
	language = {en},
	urldate = {2019-11-13},
	journal = {EBioMedicine},
	author = {Toh, Tzen S. and Dondelinger, Frank and Wang, Dennis},
	month = sep,
	year = {2019},
	pages = {607--615},
	file = {Toh et al. - 2019 - Looking beyond the hype Applied AI and machine le.pdf:/home/stephen/Zotero/storage/FT9ZZND8/Toh et al. - 2019 - Looking beyond the hype Applied AI and machine le.pdf:application/pdf}
}

@article{huang_more_2017,
	title = {More {Is} {Better}: {Recent} {Progress} in {Multi}-{Omics} {Data} {Integration} {Methods}},
	volume = {8},
	issn = {1664-8021},
	shorttitle = {More {Is} {Better}},
	url = {http://journal.frontiersin.org/article/10.3389/fgene.2017.00084/full},
	doi = {10.3389/fgene.2017.00084},
	language = {en},
	urldate = {2019-11-13},
	journal = {Frontiers in Genetics},
	author = {Huang, Sijia and Chaudhary, Kumardeep and Garmire, Lana X.},
	month = jun,
	year = {2017},
	pages = {84},
	file = {Huang et al. - 2017 - More Is Better Recent Progress in Multi-Omics Dat.pdf:/home/stephen/Zotero/storage/XJHK6HID/Huang et al. - 2017 - More Is Better Recent Progress in Multi-Omics Dat.pdf:application/pdf}
}

@article{lau_bayesian_2007,
	title = {Bayesian {Model}-{Based} {Clustering} {Procedures}},
	volume = {16},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186007X238855},
	doi = {10.1198/106186007X238855},
	abstract = {This paper establishes a general framework for Bayesian model-based clustering, in which subset labels are exchangeable, and items are also exchangeable, possibly up to covariate eﬀects. It is rich enough to encompass a variety of existing procedures, including some recently discussed methodologies involving stochastic search or hierarchical clustering, but more importantly allows the formulation of clustering procedures that are optimal with respect to a speciﬁed loss function. Our focus is on loss functions based on pairwise coincidences, that is, whether pairs of items are clustered into the same subset or not.},
	language = {en},
	number = {3},
	urldate = {2019-11-13},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Lau, John W and Green, Peter J},
	month = sep,
	year = {2007},
	pages = {526--558},
	file = {Lau and Green - 2007 - Bayesian Model-Based Clustering Procedures.pdf:/home/stephen/Zotero/storage/YBX3V8IR/Lau and Green - 2007 - Bayesian Model-Based Clustering Procedures.pdf:application/pdf}
}

@article{rogers_investigating_2008,
	title = {Investigating the correspondence between transcriptomic and proteomic expression profiles using coupled cluster models},
	volume = {24},
	issn = {1460-2059, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btn553},
	doi = {10.1093/bioinformatics/btn553},
	abstract = {Motivation: Modern transcriptomics and proteomics enable us to survey the expression of RNAs and proteins at large scales. While these data are usually generated and analyzed separately, there is an increasing interest in comparing and co-analyzing transcriptome and proteome expression data. A major open question is whether transcriptome and proteome expression is linked and how it is coordinated.},
	language = {en},
	number = {24},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Rogers, Simon and Girolami, Mark and Kolch, Walter and Waters, Katrina M. and Liu, Tao and Thrall, Brian and Wiley, H. Steven},
	month = dec,
	year = {2008},
	pages = {2894--2900},
	file = {Rogers et al. - 2008 - Investigating the correspondence between transcrip.pdf:/home/stephen/Zotero/storage/ZBYXIURU/Rogers et al. - 2008 - Investigating the correspondence between transcrip.pdf:application/pdf}
}

@article{ahmed_public_2019,
	title = {A {Public} {BCR} {Present} in a {Unique} {Dual}-{Receptor}-{Expressing} {Lymphocyte} from {Type} 1 {Diabetes} {Patients} {Encodes} a {Potent} {T} {Cell} {Autoantigen}},
	volume = {177},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867419305057},
	doi = {10.1016/j.cell.2019.05.007},
	abstract = {T and B cells are the two known lineages of adaptive immune cells. Here, we describe a previously unknown lymphocyte that is a dual expresser (DE) of TCR and BCR and key lineage markers of both B and T cells. In type 1 diabetes (T1D), DEs are predominated by one clonotype that encodes a potent CD4 T cell autoantigen in its antigen binding site. Molecular dynamics simulations revealed that this peptide has an optimal binding register for diabetogenic HLADQ8. In concordance, a synthetic version of the peptide forms stable DQ8 complexes and potently stimulates autoreactive CD4 T cells from T1D patients, but not healthy controls. Moreover, mAbs bearing this clonotype are autoreactive against CD4 T cells and inhibit insulin tetramer binding to CD4 T cells. Thus, compartmentalization of adaptive immune cells into T and B cells is not absolute, and violators of this paradigm are likely key drivers of autoimmune diseases.},
	language = {en},
	number = {6},
	urldate = {2019-11-13},
	journal = {Cell},
	author = {Ahmed, Rizwan and Omidian, Zahra and Giwa, Adebola and Cornwell, Benjamin and Majety, Neha and Bell, David R. and Lee, Sangyun and Zhang, Hao and Michels, Aaron and Desiderio, Stephen and Sadegh-Nasseri, Scheherazade and Rabb, Hamid and Gritsch, Simon and Suva, Mario L. and Cahan, Patrick and Zhou, Ruhong and Jie, Chunfa and Donner, Thomas and Hamad, Abdel Rahim A.},
	month = may,
	year = {2019},
	pages = {1583--1599.e16},
	file = {Ahmed et al. - 2019 - A Public BCR Present in a Unique Dual-Receptor-Exp.pdf:/home/stephen/Zotero/storage/W34YAEKW/Ahmed et al. - 2019 - A Public BCR Present in a Unique Dual-Receptor-Exp.pdf:application/pdf}
}

@article{banerjee_bayesian_nodate,
	title = {Bayesian learning of joint distributions of objects},
	abstract = {There is increasing interest in broad application areas in deﬁning ﬂexible joint models for data having a variety of measurement scales, while also allowing data of complex types, such as functions, images and documents. We consider a general framework for nonparametric Bayes joint modeling through mixture models that incorporate dependence across data types through a joint mixing measure. The mixing measure is assigned a novel inﬁnite tensor factorization (ITF) prior that allows ﬂexible dependence in cluster allocation across data types. The ITF prior is formulated as a tensor product of stick-breaking processes. Focusing on a convenient special case corresponding to a Parafac factorization, we provide basic theory justifying the ﬂexibility of the proposed prior and resulting asymptotic properties. Focusing on ITF mixtures of product kernels, we develop a new Gibbs sampling algorithm for routine implementation relying on slice sampling. The methods are compared with alternative joint mixture models based on Dirichlet processes and related approaches through simulations and real data applications.},
	language = {en},
	author = {Banerjee, Anjishnu and Murray, Jared and Dunson, David B},
	pages = {9},
	file = {Banerjee et al. - Bayesian learning of joint distributions of object.pdf:/home/stephen/Zotero/storage/JWU76EPZ/Banerjee et al. - Bayesian learning of joint distributions of object.pdf:application/pdf}
}

@article{lock_joint_2013,
	title = {Joint and individual variation explained ({JIVE}) for integrated analysis of multiple data types},
	volume = {7},
	issn = {1932-6157},
	url = {http://projecteuclid.org/euclid.aoas/1365527209},
	doi = {10.1214/12-AOAS597},
	abstract = {Research in several fields now requires the analysis of datasets in which multiple highdimensional types of data are available for a common set of objects. In particular, The Cancer Genome Atlas (TCGA) includes data from several diverse genomic technologies on the same cancerous tumor samples. In this paper we introduce Joint and Individual Variation Explained (JIVE), a general decomposition of variation for the integrated analysis of such datasets. The decomposition consists of three terms: a low-rank approximation capturing joint variation across data types, low-rank approximations for structured variation individual to each data type, and residual noise. JIVE quantifies the amount of joint variation between data types, reduces the dimensionality of the data, and provides new directions for the visual exploration of joint and individual structure. The proposed method represents an extension of Principal Component Analysis and has clear advantages over popular two-block methods such as Canonical Correlation Analysis and Partial Least Squares. A JIVE analysis of gene expression and miRNA data on Glioblastoma Multiforme tumor samples reveals gene-miRNA associations and provides better characterization of tumor types.},
	language = {en},
	number = {1},
	urldate = {2019-11-13},
	journal = {The Annals of Applied Statistics},
	author = {Lock, Eric F. and Hoadley, Katherine A. and Marron, J. S. and Nobel, Andrew B.},
	month = mar,
	year = {2013},
	pages = {523--542},
	file = {Lock et al. - 2013 - Joint and individual variation explained (JIVE) fo.pdf:/home/stephen/Zotero/storage/6RPYGPE4/Lock et al. - 2013 - Joint and individual variation explained (JIVE) fo.pdf:application/pdf}
}

@article{kiddle_temporal_2010,
	title = {Temporal clustering by affinity propagation reveals transcriptional modules in {Arabidopsis} thaliana},
	volume = {26},
	issn = {1367-4803, 1460-2059},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btp673},
	doi = {10.1093/bioinformatics/btp673},
	abstract = {Motivation: Identifying regulatory modules is an important task in the exploratory analysis of gene expression time series data. Clustering algorithms are often used for this purpose. However, gene regulatory events may induce complex temporal features in a gene expression proﬁle, including time delays, inversions and transient correlations, which are not well accounted for by current clustering methods. As the cost of microarray experiments continues to fall, the temporal resolution of time course studies is increasing. This has led to a need to take account of detailed temporal features of this kind. Thus, while standard clustering methods are both widely used and much studied, their shared shortcomings with respect to such temporal features motivates the work presented here.},
	language = {en},
	number = {3},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Kiddle, S. J. and Windram, O. P. F. and McHattie, S. and Mead, A. and Beynon, J. and Buchanan-Wollaston, V. and Denby, K. J. and Mukherjee, S.},
	month = feb,
	year = {2010},
	pages = {355--362},
	file = {Kiddle et al. - 2010 - Temporal clustering by affinity propagation reveal.pdf:/home/stephen/Zotero/storage/9BS9TH8L/Kiddle et al. - 2010 - Temporal clustering by affinity propagation reveal.pdf:application/pdf}
}

@article{argelaguet_multiomics_2018,
	title = {Multi‐{Omics} {Factor} {Analysis}—a framework for unsupervised integration of multi‐omics data sets},
	volume = {14},
	issn = {1744-4292, 1744-4292},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.15252/msb.20178124},
	doi = {10.15252/msb.20178124},
	language = {en},
	number = {6},
	urldate = {2019-11-13},
	journal = {Molecular Systems Biology},
	author = {Argelaguet, Ricard and Velten, Britta and Arnol, Damien and Dietrich, Sascha and Zenz, Thorsten and Marioni, John C and Buettner, Florian and Huber, Wolfgang and Stegle, Oliver},
	month = jun,
	year = {2018},
	file = {Argelaguet et al. - 2018 - Multi‐Omics Factor Analysis—a framework for unsupe.pdf:/home/stephen/Zotero/storage/VRQ47M3N/Argelaguet et al. - 2018 - Multi‐Omics Factor Analysis—a framework for unsupe.pdf:application/pdf}
}

@article{knowles_nonparametric_nodate,
	title = {Nonparametric {Bayesian} {Sparse} {Factor} {Models} with application to {Gene} {Expression} modelling},
	language = {en},
	author = {Knowles, David and Ghahramani, Zoubin},
	pages = {21},
	file = {Knowles and Ghahramani - Nonparametric Bayesian Sparse Factor Models with a.pdf:/home/stephen/Zotero/storage/38FTGR6U/Knowles and Ghahramani - Nonparametric Bayesian Sparse Factor Models with a.pdf:application/pdf}
}

@article{zhang_probabilistic_2019,
	title = {Probabilistic cell-type assignment of single-cell {RNA}-seq for tumor microenvironment profiling},
	volume = {16},
	issn = {1548-7091, 1548-7105},
	url = {http://www.nature.com/articles/s41592-019-0529-1},
	doi = {10.1038/s41592-019-0529-1},
	language = {en},
	number = {10},
	urldate = {2019-11-13},
	journal = {Nature Methods},
	author = {Zhang, Allen W. and O’Flanagan, Ciara and Chavez, Elizabeth A. and Lim, Jamie L. P. and Ceglia, Nicholas and McPherson, Andrew and Wiens, Matt and Walters, Pascale and Chan, Tim and Hewitson, Brittany and Lai, Daniel and Mottok, Anja and Sarkozy, Clementine and Chong, Lauren and Aoki, Tomohiro and Wang, Xuehai and Weng, Andrew P and McAlpine, Jessica N. and Aparicio, Samuel and Steidl, Christian and Campbell, Kieran R. and Shah, Sohrab P.},
	month = oct,
	year = {2019},
	pages = {1007--1015},
	file = {Zhang et al. - 2019 - Probabilistic cell-type assignment of single-cell .pdf:/home/stephen/Zotero/storage/ZZXH4FTL/Zhang et al. - 2019 - Probabilistic cell-type assignment of single-cell .pdf:application/pdf}
}

@article{savage_discovering_2010,
	title = {Discovering transcriptional modules by {Bayesian} data integration},
	volume = {26},
	issn = {1460-2059, 1367-4803},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btq210},
	doi = {10.1093/bioinformatics/btq210},
	abstract = {Motivation: We present a method for directly inferring transcriptional modules (TMs) by integrating gene expression and transcription factor binding (ChIP-chip) data. Our model extends a hierarchical Dirichlet process mixture model to allow data fusion on a geneby-gene basis. This encodes the intuition that co-expression and co-regulation are not necessarily equivalent and hence we do not expect all genes to group similarly in both datasets. In particular, it allows us to identify the subset of genes that share the same structure of transcriptional modules in both datasets.},
	language = {en},
	number = {12},
	urldate = {2019-11-13},
	journal = {Bioinformatics},
	author = {Savage, Richard S. and Ghahramani, Zoubin and Griffin, Jim E. and de la Cruz, Bernard J. and Wild, David L.},
	month = jun,
	year = {2010},
	pages = {i158--i167},
	file = {Savage et al. - 2010 - Discovering transcriptional modules by Bayesian da.pdf:/home/stephen/Zotero/storage/SSTYTVJT/Savage et al. - 2010 - Discovering transcriptional modules by Bayesian da.pdf:application/pdf}
}

@article{nguyen_ten_2019,
	title = {Ten quick tips for effective dimensionality reduction},
	volume = {15},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1006907},
	doi = {10.1371/journal.pcbi.1006907},
	language = {en},
	number = {6},
	urldate = {2019-11-13},
	journal = {PLOS Computational Biology},
	author = {Nguyen, Lan Huong and Holmes, Susan},
	editor = {Ouellette, Francis},
	month = jun,
	year = {2019},
	pages = {e1006907},
	file = {Nguyen and Holmes - 2019 - Ten quick tips for effective dimensionality reduct.pdf:/home/stephen/Zotero/storage/2C94LTA4/Nguyen and Holmes - 2019 - Ten quick tips for effective dimensionality reduct.pdf:application/pdf}
}

@article{gelman_prior_2017,
	title = {The prior can generally only be understood in the context of the likelihood},
	volume = {19},
	issn = {1099-4300},
	url = {http://arxiv.org/abs/1708.07487},
	doi = {10.3390/e19100555},
	abstract = {A key sticking point of Bayesian analysis is the choice of prior distribution, and there is a vast literature on potential defaults including uniform priors, Jeﬀreys’ priors, reference priors, maximum entropy priors, and weakly informative priors. These methods, however, often manifest a key conceptual tension in prior modeling: a model encoding true prior information should be chosen without reference to the model of the measurement process, but almost all common prior modeling techniques are implicitly motivated by a reference likelihood. In this paper we resolve this apparent paradox by placing the choice of prior into the context of the entire Bayesian analysis, from inference to prediction to model evaluation.},
	language = {en},
	number = {10},
	urldate = {2019-11-13},
	journal = {Entropy},
	author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
	month = oct,
	year = {2017},
	note = {arXiv: 1708.07487},
	keywords = {Statistics - Methodology},
	pages = {555},
	annote = {Comment: 13 pages},
	file = {Gelman et al. - 2017 - The prior can generally only be understood in the .pdf:/home/stephen/Zotero/storage/ENW9JYYL/Gelman et al. - 2017 - The prior can generally only be understood in the .pdf:application/pdf}
}

@article{blei_variational_2017,
	title = {Variational {Inference}: {A} {Review} for {Statisticians}},
	volume = {112},
	issn = {0162-1459, 1537-274X},
	shorttitle = {Variational {Inference}},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773},
	doi = {10.1080/01621459.2017.1285773},
	language = {en},
	number = {518},
	urldate = {2019-11-13},
	journal = {Journal of the American Statistical Association},
	author = {Blei, David M. and Kucukelbir, Alp and McAuliffe, Jon D.},
	month = apr,
	year = {2017},
	pages = {859--877},
	file = {Blei et al. - 2017 - Variational Inference A Review for Statisticians.pdf:/home/stephen/Zotero/storage/TYA8I56X/Blei et al. - 2017 - Variational Inference A Review for Statisticians.pdf:application/pdf}
}